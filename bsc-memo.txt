"Software Security as a Financial and Operations Research Problem"
Jukka Paulin

Keywords:
Computer science
Software development, Software security, Software engineering
Operations research
Organizational psychology
AI enabled development of code

2017-2026

Chapter I: What we are actually researching?

The purpose of this Bachelor of Technology Thesis is to introduce
software security, and investigate whether there are project management
models that can lead to improvement in Software Security (along with
other desired quality indicators), without sacrificing timetable and/or
project costs.

Many signs point to the fact that "quality at one go" is way better than
patching things, trying ad-hoc panicky moves to evade deadline
crises. The business environment in which software is being made makes
probably its own flavoring to the approaches used. 

Chapter II Scope revisited: What is NOT in this thesis

The thesis also weeds out certain areas, that are close to software
security, but beyond the scope: 
- information security
- contract breaches in software projects
- social engineering attacks

So this thesis is about how to MAKE Software (source code, 
and the artefact running live) as secure as possible, 
understanding that the security is about the human
process that creates the software.

Note; in this project, if we have to put emphasis on either 
static source point-of-view of software, or on the "live" 
process running out of the compilation of the source, 
we will be concentrating on the software-as-static source
point of view.

Being a compass for a powerboat?

I think software teams don't necessarily lack skills to make secure software,
but they might be thin on the will, inspiration, and management support.
Developers under normal circumstances, are often loaded with work, and
security is not the topmost priority in many organizations.

With writing this thesis, I want to provide some idea of a "compass"
to the right direction.

## Technical metrics - not measuring security of code

There can be a lot of technical metrics about a software, that do not
measure its true security. Often the metrics are geared towards
making sure the project delivers on time and within budget.

In summary, suffice to say that most traditional code metrics
measure the size, complexity, quality, or delivery progress. 
But not security.

Only metrics that directly track security flaws (number of 
vulnerabilities found, security-focused static analysis) truly measure security.


I have perhaps come up with some new use of metaphors for
software. One of those is the "iceberg", which is part of the theory
of Software drift; developers, in the everyday crave for speedy
development, might resort to using a particular library or module
based on purely one key functionality that it provides - ignoring
the "cost" of carrying around a big chunk of code - sometimes
without knowing its security level or status. It is, a team might
well be equipped with proper horsepower, and sonar technology, but
they fail to look forward into the impeding crash with a wall of an
iceberg; so in retrospect, the decision was not about velocity,
but direction -- as viewed from above.


Chapter 3: The Introduction - Why Software Security Matters?

We're entering a world where software makes a great deal of
our daily lives. Software is a critical part of both "actually
useful" as well as the trivial and fun stuff in our lives.
Nevertheless, in both cases we'd like to be assured of certain
things: that a life-saving thing like the brakes of our car,
or the control unit of an elevator, or the software used by
air traffic controllers (ATC personnel)

Then again, it doesn't excuse bad behavior either, even if
we are talking about a little furry children's toy that
has a microphone and an Internet connection built-in. We certainly
don't expect nor allow that kind of a toy to turn into
a spying ear in our homes.

Software developers ('devs') are at the heart of this process.
They are hired by corporations to do work that ranges from
A to Z; often times developers themselves might not be
the core subject matter experts, ie. a developer working on
a software that ultimately is _used by_ a person working as
Air Traffic Controller.

So there's a fundamental separation of concerns; an in reality,
there are even more, hierarchical separations of concerns:
the corporation producing this ATC software most likely has
personnel in management positions, who might not do the
actual development (coding) work at all.

The separation of concerns requires coordination, so that
the software gets done properly: that it fits the particular
purpose (the very reason it is being written); that it
does not do things which are bad (security issues); and
to count for the case of real world, the corporation that
does the software must most likely also maintain its processes
viable cost-wise: otherwise, one day the corporation finds
out it has lost the deal to a competitor.  

---

Problem-solving strategy for this Bachelor's thesis:

The First Question:

 "Can secure programming be fun and adapted as a new style?"

Does Software security really have to feel a "drudge", like making
your bed every morning? Or can it actually be a natural improvement
in the software methodology, so to produce more secure software without
extra effort, once the developers have accustomed to the style?

Second Question:

 "Can the good-quality programming be adopted team-wide and be
  rather static, without constant rat race with vulnerabilities?"

Finding the relations between types of vulnerabilities and
the amendments in software development process (SDP). We assume that
change always incurs some costs, and since the paper is about exploring
"minimizing costs while maintaining or improving quality" this is
a very central question.

Overview: Project models in Software Engineering

* introducing what a SW development project model is
* real process can deviate from a model
* deviations are something that can be measured
  - another question is, however, do teams measure it?
* metrics can be introduced to track deviation and development progress
* how do metrics communicate with security of a software?
* how can feedback guide the real process towards an optimum?
* should project model change during time?
  - adapting new model
  - decision-makers? Who carries out executive operations in a SW team?
  - see also [2:GameTheory]

 -> gate (checkpoint)

'Hacking' is something that doesn't particularly care about
or need a project model. There are numerous tales (often admiring
in tone) of hackers who can pour thousands of lines of software,
laying down major chunks of the project at one go; however, what
might be untold in these tales is the long-term effects of the
heroic deeds: other participants in the project might have tough
time adjusting to the change, and if the chief (often called
"wizard" or "guru") isn't too keen on documenting what he does,
the team might be completely lost.

A project model means a template of the instructions that
would be given to a software team, in order to make progress,
and produce good quality software.

Project models have evolved throughout the (relatively short)
history of software.

WIP: There's a possibility that to achieve the best
result for our metrics (balancing security with costs)
we need to construct a new Model.
WIP2: Feedback comes rather late in security related matters.
In fact, a vulnerability often lives for a few years until
it is discovered. How to overcome this technical limitation
in giving effective feedback?

Extras: Outsourcing projects over services on Internet
======================================================
HackerOne is a service where paid bounty hunters are looking
for vulnerabilities in software and services, and then
they disclose these in a ethical manner (so that the company
whose product has the glitch has advance warning about it).
According to Wikipedia the company had approximately 100.000
"workers" and had paid 14 million USD in bounties.

Fiverr

To recap the highlights of the project models:

pre-1950s: no models at all?
1990s:     was there a dominant model?
2000s:     new experimentations; Extreme Programming (pairwise), etc.
2005-2017: Agile is all the rage

No security concerns before the TCP/IP aka Internet?

When did security become a concern of software?
Connected systems
Early networked systems were deemed "proprietary enough"
Access to medium is a key
Vampire taps in early Local Area Networks
Fiber does not provide any special security

Principles of security engineering

See: Ross Anderson

Project models throughout time
==============================
Scrum 
DSDM
Extreme Programming (XP)
Crystal Methods
Adaptive software development
Pragmatic Programming
Feature driven development
Gilb-EVO

Software authoring in real-world is an iterative process.
Regardless of the "awareness" of this fact, the development
in any industrial-grade extent will always be something
else than just a one-off coding session.

We could make a distinction here what is a project vs
a one-off project. For example, a piece of front-end
code in a web page that exists for 7 days during a
marketing event is not considered a software project.
This kind of product can indeed be done using a template
functionality in a CMS (content management system).

The project often lives for years. Some of the initial design
decisions are ones that are difficult to revert; thus a
very good question is how can a project keep its fluency
and ability to adopt to new challenges, requirements, and
possibly environment?

Organizations have tackled this question in various ways
- technology evaluations
- separating design from actual implementation

Complete rewrites of a project do happen. This is often
called 'starting from the scratch'. As the project gets bigger,
a complete rewrite becomes often prohibitively expensive.
Modularity of the software should optimally make iterations,
testing and - if required - the rewriting easier.

Before the prevalence of shared code ('open source', libraries)
software teams sometimes had to spend considerable time
up-front doing the "tools" or pieces of code that were
kind of auxiliary (secondary; but very important, nevertheless)
to the actual goal of the project. For example, software using
cryptography to secure data in transit, might have to implement
first so-called "big integer" libraries. These are structures
and algorithms that are used to build the encryption/decryption
code.

Side alley: what is a language didn't have hash tables ("dictionaries")
======================================================================

A thing that nowadays is taken for granted is "hash" support
in a programming language. Hashes are bags of data, that can
be addressed with a key. They are very useful and powerful
feature of a language.

In the "back end", if one were to
design a hash, there is plenty of academic literature available,
yet plenty of ways of both implementing the hash in
either unoptimal or plain wrong way. Errors in hash
implementation would lead to data corruption. Hashes
are often used in a few places:
* digesting a message (to check for message corruption)
* digital signatures
* dictionaries
* configuration systems



After open source became popular, it was possible to
rapidly develop core functionality. Some popular libraries
in fact can save hundreds or thousands of workman-hours
from individual teams. In JavaScript development, for example,
there are very useful libraries that deal with
web browser incompatibilities; lack of certain necessary and
useful language structures in JavaScript itself (library
inclusion mechanisms), and so on.

------------------------------------------------------------

Defining metrics, processes, and variables

* how to measure change from altering the variables
* no direct, absolute "S->R" but more likely a gradual
  response, See: https://en.wikipedia.org/wiki/Stimulus%E2%80%93response_model

To have research-able results, we must have some control over
the process ('variables'). The variables are things that can be
altered (my management). Teams respond to new rules probably
in somewhat unpredictable way; this is the same as in economics:
the response of a group of people cannot be foretold exactly.

For the research method it's quite important to think, how
the response (shown in metrics) is regarded. Let's say there's
a change in variable 'Sprint length'. This variable is easy,
since the team cannot arbitrarily choose not to obey the change.

What about a technical measure, like 'Maximum allowed defect
count'? Again, the process adherence defines how the team
reacts. If it's a hard limit, in a way that simply the team
is not allowed to proceed until the bugs have been fixed to lower
count, it's easier for our research to relate to this. If
it's a soft threshold and team can continue doing code as
if there wasn't a maximum amount on defects, it's harder to
establish what the real change would be from such change.

Variable list

Sprint length
Maximum allowed defect count
Technical Debt limits
Policy of Features Not Completed


Agile takes a stance on what happens to Features (Items)
not completed during a sprint. 


------------------------------------------------------------

- no project model ("ad hoc")
- waterfall
- iterative (aka incremental model)
- see https://en.wikipedia.org/wiki/Waterfall_model 

Some of the apparent "change" in methodologies might be 

[WIP] More rigorous limits and dissecting what the different
      models were, when have they emerged, are they still
      in use, how one can identify being a user, and
      pros/cons of each

Characteristics (parameters) of software projects

scope
costs
phases
timetable

Scope: How large and feature-rich the software is

Costs:
- cost of tooling
- time used (salary)
- licensing
- hardware if special needs
- hosting costs
- one-time vs. continuous
- the "sunk cost" explained
- typical sunk costs were huge for waterfall projects
  as well as any other projects that never get to use

======================================
Ballpark formula for costs of software

producer-side view
C = outselling price for a project of F features

Inputs
  N = number of features
	
-------------------------
  C = ( F + [h*A*R] ) * M
-------------------------

A     = aggregate work (hours) per a Feature
F     = fixed costs internal for producer
h * R = salary (man hour costs)
M     = profit margin (quantifier)
======================================

In fixed price contracts, the M cannot be freely taken.
Thus the software company tries to alter F, h and
R. R is quite fixed also, given a steady crew (organic
employees). Thus the variables are F and h.

Skill transfer over to next project
==========================================
- interesting practical point in terms of costing
- load factor forgiving, individuals learn from projects
  -given that the technology is not obsoleted by the next
	 project start
	 - thus "stable" and robust environments would be
	   beneficial for corporations, because then the
		 corporations can gain a competitive edge by
		 specializing in a particular Tech Stack

Time-specific items of the Characteristics
==========================================

* first version ship date
* "1.0" version ship (first functional version of SW)

Phases of software engineering

conception
initiation
analysis of requirements
formulating a spec for bidding phase
bidding (competing)
design
implementation
testing
deployment
maintenance phase
decommissioning (end of life)

The CI cycle composed of
- implementing
- documenting
- testing
- deployment

------

Change

Software, by its very nature, is evolving. One of the pitfalls of
early "waterfall" project management models was that Teams spent
enormous time and effort in defining software up-front, without
making prototypes. The waterfall attitude is that of space missions:
everything has to be known and taken into account beforehand.

This was later countered by the YAGNI in Agile
methodologies ("You ain't gonna need it")
See [5] for great story of seemingly eternal software project

Process parts in Software Development
- the Agile model
  - cycles

A process is often defined for software development in order
to mitigate the negative effects of "having to re-invent a wheel".
Agile (the Manifesto) is one of the most talked-about and
currently probably most widely used software development methodology.
Agile development is a people-first attitude and a counter-force
to the "tar-pit" effect, which was observed by 



=========================================================================
Major Building steps for paper
=========================================================================
- pose the central questions as topic says: "Operations Research" problem
  > so introduce all that is promised
  > implement both a Financial and OR viewpoint
- quantifying a SW project
  - by the process itself
  - documenting the goals of a software project
  - tracking in time (usually done with a Agile tool)
    - daily sampling?
    - enough log of code repository (ie. complete 'git' history available)
      to do postmortem analyses
      
- add empirical testing to disprove or prove the hypotheses

- set up multiple, close-enough software projects that can
  differentiate the results
- set up the framework for measurement, similar in all projects

- consider technical limitations to the lab;

- A practical problem:
   how can there be several Software projects whose nature is similar,
   but the results are different?


Tracking items for writing process
==================================

[WIP:Figure]	add a figure (graph, image)


============
Introduction
============

The Purpose of software: Utility

Software Engineering produces computer code and other artefacts, which
are executed by a Computer. This ('software') can be either visible
or invisible part of a commodity that has an utility for its Users.

Depending on whether a project is commercial (tailored software) or
a open source project, there can be quite different stakeholder
groups and even a very different philosophy in design and practical
issues. 

Open source software is produced "by the people, for the people"
and often solves a common problem. 

Shrink-wrapped, commercial projects are done often for 
a single customer, who is willing to significantly
put resources behind the development. 

Characteristics of Commercial vs. FLOSS software

Both:
Span
Scope
Contract

Both:
Changing team members (possibly)
Documentation
Code
Artefacts
Supporting infrastructure for builds

Software Drift: "It was never supposed to be there"

Security breaches are enabled by many things, but one of the
factor that creeps from human assumptions is that the software
team responsible for developing the code might never imagine
the software to be used in a particular setting.

Especially if one looks at the open source community, many
projects are described as "just a little ..." this-and-that. So
there are humble beginnings, and often the software might
be custom built just to serve a transient need. Or so it is
thought - because we are lazy as a community, and programmers
especially believe the mantra of DRY (Don't Repeat Yourself),
it's a natural inclination to use existing solutions as long
as they fit the gap. 

"Small web servers" then one day find their way not only
to rather closed and protected intranets, but indeed are out
in the wild, facing all the hostile network traffic the world
of Internet can bring about. These same software are also running
perhaps as a utility glue in children's toys and what-not -
essentially in as many places as you could NOT imagine.
People might have forgotten (during a typical lifespan of 5-10
years) the origins of the software, and might take for granted
certain security properties - "since it (software) is popular
and has been time-tested".

For example, some small utility programs nowadays are found as
embedded components in many of the so-called "IoT" devices. A piece
of software that originally was supposed to be almost a passing
"patch", to satisfy a particular need, often keeps persisting,
gathering more code, and the software "drifts" to random places.

This very factor is part of the Open Source movement's power:
software is omnipresent and easily available, without limitations
placed upon its use. The same philosophy implies a kind of
'caveat emptor' (know what you are doing, as a developer).


Chapter ?X: Why programming is mentally hard?

A simple recipe, from anyone who has studied computer science, is
that 'data structures + algorithms = code'. So in theory it would
be quite simple to do programming. Since algorithms have become
very abundant, being development in laboratories, universities, and
often also being published, we'd intuitively think that software
would be even easier than placing LEGO blocks on top of each
other.

The problem emerges from these: 
 - there are gray areas, not clear-cut cases

"Gray area" ?

The gray areas have to do with ambiguity of drawing a line in classifications,
for example. Let's say I want to 'detect operating system'. We have 3
OS available: Windows, MAC, and Linux. It is superficially an easy thing to
do. There's an environment variable (a string) available and it is set to
contain information that is input to our function.

So return value is one of 4 possible values: three choices, and the error
case ('unknown') where we couldn't determine the OS.

We have to communicate this properly. It would be very "nice" to always
fall into one OS, since otherwise the downstream developer will have
to make the decision on the gray area: how to proceed with a 'unknown'.

Tallying up the uncertainty of Gray areas
- leads to combinatorial amount of branches
- coverage comes to play
- also a question of understanding, communication
- but remember: hackers are only looking for holes, not explanations
  - management might be interested in explanations
- so called "water tight code"

---

IoT era paradox: imbalanced whole
- increasing prevalence; devices abound
- manufacture is cheap
- as devices are trying to be kept minimal in price, software development
  costs are also being curbed
  -> insecurity
- a kind of imbalance between the nature of hardware vs. software
  - "once right" hardware design can be replicated with low costs
  - software often needs more tending, as a modern-size software project
    can never be "proven correct"
- devices coming into more "physical" and real danger -imposing
  use cases


Technical principle of Computers and Software: Short intro
----------------------------------------------------------
Software is comprised of code. Code is language, that describes
(ultimately) arithmetic operations that the computer will
execute. Computer can manipulate 'bits': smallest digital units
of data. These bits can be used to represent meaningful
concepts in the Domain of the software.

Computer code is representation of the actions that the CPU and
other processors shall execute, in combination with memories (RAM)
and static storage (hard disk, other media). The code directs
computing.
[See: Von Neumann architecture]

Metrics of Software Quality
---------------------------
* [WIP] The distinction of quality metrics in Static source code
  vs. the overall (security) functional quality of a program
  when it is being run (live)

The quality (goodness) of a software has many metrics. One of them
is the security:

  a) can the software be fooled to do things it
     wasn't supposed to, and
     
  b) can a malicious user "break" the software and use to it go
     through security perimeters that were supposed to keep him out?

Security is often overlooked in production

Security is one of the hardest parts of software. It is considered
a kind of "secondary" aspect, since security by itself does not
directly contribute to the perceived value a Software has. Software
was originally written to solve a problem, or to provide automation
and service. Thus security comes in as a side effect; it can be
described as the amount of unintended malicious (harmful) use
cases that can be executed.

What is Secure programming?

Making a secure product takes more than producing secure code, per
se. A product runs on a platform; a product is being developed
using computers and software, which can already be a vulnerability
vector in some cases;

- algorithm quality
  - random number generation
- data disclosure
  - session restart / force vulnerabilities
  - if you reuse (even accidentally) data in security protocols,
    you most likely give attacker a big hand
- "beyond your abstraction": looking at the computer, not just
  JavaScript or Java and JVM
  - some things get broken due to the nature of computer as
    something that acts in shady ways, compared to what you as
    programmer think

"Computers don't really know what they are doing"

Computer, and software, lacks "sentient introspection": it doesn't
know when it is being fooled. If a randomness algorithm relies
on a division operation, and the divisor is the time difference
between two events (supposed to be some kind of "random" number
between 1 - 1,000,000,000 since we measure nanoseconds), it will
be a major disruptor if an attacker can "drive" the process so that
the difference is always 1 ns. Thus the division is X/1 which is
always X itself: that might be a leak of data.

We humans often have "wit" and general intelligence, which can
defend us against certain class of evident attacks, but computers
work just as they are told to. Thus the intelligence of a system
(software) is as good as the wits of the developers. Note plural:
not just "you", but all developers that have done code that you
rely on; it might be libraries, kernel, core BIOS, etc.


Chapter ?X: Software Testing

Definition of "correct" vs. good-enough 
- All software will have bugs
  - only very simple pieces of code can be VERIFIED to be "correct"
- Finding sweet spots in methods
  - not a formality?
  - efficiency of writing minimal but sufficient amount of tests
    goes up with programmer's experience in the subject
- Methods of testing
  - black box
  - gray box
  - white box testing
- Do the "vulnerability seriousness" rankings follow some kind of pattern / relation
   to the effort in SW engineering ?
  - ie. can we predict where security should be increased in a Software project?

1) Logic level testing
2) Real: Stack frames, overruns etc. accounted for

The Ishikawa (fish-bone) diagram for Root Cause Analysis


Sub-Chapter: Nature of Discovering Bugs

Discovering bugs can happen basically in various ways:

  accidentally,
  by intent,
  during Quality Assurance;
  and coming as feedback
  from the wild (a vulnerability disclosure).

The important thing about bug discovery is "When" and "Where". Financially
it makes a big difference, whether bug is discovered inside or outside
the software house. Outside discoveries often have the potential of
causing direct or indirect losses for the company and its clients.

 - a developer reading source code, haphazardly, and stumbling upon a bug
   (piece of source code that looks suspicious)
 - writing unit tests and running them -> show a bug
 - bug from "the wild": there's a disclosure of vulnerability
 - a specific test of Quality Assurance called "penetration testing" 

Even a developer who has written the code ("author") may have trouble
deciding upon the consequences of a "fix" - editing the source code
to a different state. Unit tests may guard against problematic changes;
see [Unit tests: Coverage]

Undoing benevolent source code change by accident

Other developers may not always understand changes. I was once working in
a project where a bug was looming due to the obscurity of JavaScript,
a language that has had a troubled past 


Chapter ?X:

To complete this thesis, it's necessary to tie together the human
aspects of computing and the financial / technological results.
IT companies throughout ages have actually been keen on marketing
the secret of their success as being in "Right people".

A kind of no-brainer restatement is this phrase:
"...this is further proof of what HR professionals have long
said: Success is based on finding the right people for the right
obs."
(from: www.inc.com/articles/2002/01/23815.html)

We cannot however dig too deep into human psychology, so our
first priority is to find effective methods, based on some set
of metrics, so that we can map

A -> e -> S

Actions (A) taken by manager(s), have an effect, which produces
some set of changes to software metrics (S).

S is thus the metrics matrix.

Since we are dealing with time, we need a time dimension. This makes
the matrix an array. Otherwise the matrix contains metrics that
are quite self-evident:

[] code hygiene level (ie. Sonar or other static scanner)
[] # of known security defects
[] # of other violations in code quality
[] # hours for this time period
[] # increment in feature completeness (some metric)

(WIP: list the required technical and financial metrics, 3-6 altogether)

Can the PECK -model be applied

We could think of situational factors as being either external
or internal. External factors might be things like general mood
in the team (or office), financing status, etc. Internal factors
have to do with the core skills of the developers, motivation, etc.

An important question to answer is: what is the relationship between
external and internal factors? Does a great company nurture good
quality and secure software? Might it go the other way around? "Since
we're in no trouble, there's no particular pressure to do secure
software. We can sell it anyway, customers happy, everyone is happy."

A recent case that is worth thinking is mentioned in 




Chapter ?X: The nature of software vulnerabilities

Defining a vulnerability
Some central glossary
CVE identifiers


Chapter ?X: The Software Team - Human points of view

In reality, there are a lot of human-factor issues in software
engineering. Otherwise we'd probably see robots doing automated
code. People have motivation and incentives to act. An interesting
paper [2] I stumbled upon about two years prior to starting
writing this thesis, was one that introduces the roles of a Team
as viewed through mathematical "Game theory".

People have incentives to act or "be insensitive to matters";
they also have (according to paper's authors) a different
set of payoffs that direct the software development in a practically
skewed way: developers do not reap such a great extent of the fruit
of doing software, whereas product owners and sales (company reps)
are more likely to benefit from a successful software.

However the core of the problem is also the definition of
'successful software'. It is a lot about cost+feature issues on the
sales side, whereas developers are more inclined to tend for quality. 
Sales would like to push software out to clients fast, with a lot
of features, and with a competitive (preferably low, if there
is competition) price. However generally both # of features +
quality increases price, as there is more work to be done to
polish the software.

Examples of vulnerabilities
===========================

Class of security hazards: Does this project talk about viruses,
malware, or only about software defects?


Chapter ?X: Basics: Computing defined
=====================================

Computing is basically just retrieval of bits, manipulation of
the bits, and their storage back to memory. Thus described,
computing can be theoretically reverted to a 'Turing machine',
which has very simple operations on a infinite band.

In all practical sense, software is produced by people. Computer
programmers ('developers', software engineers) have the domain
knowledge and specialty to write code. In addition, a real Software
project often has many other roles as well: designers, a product
owner, etc. See: "Agile"


Software can be measured in two ways: static and dynamic.
 [WIP: Be more exact in 'measured' vs. 'analyzed'. Can software
 be "measured" in dynamic way?]

Static analysis is the software source code -level review, done
often by either people or people and tools. Tools can quickly count
the occurrence of various patterns, especially given the correct
level of inspection: typically free-text (variable and function
names chosen by developers) are transformed first systematically
to anonymous symbols, so as not to give focus on wrong things.

  It is important to remember that names and naming are one the
  key parts of program code. A name "affords" cognitive assumptions
  about the variable or function, thus proper and systematic
  use of naming is an important prerequisite to quality of code.

Examples: Naming convention in 'david' - a dependency tool

 'david' compares two sets of versions in software libraries:
  - those that are currently being used in your project vs.
  - the "available versions" of those particular libraries (on Internet)

  The tool helps a software developer judge whether he should be
  moving up to more recent versions of libraries in his project.

 Below are 10 function headers of real JavaScript code:

 function depType (opts) { ... };
 function getDependencies (manifest, opts, cb) { ... };
 function getLatestStable (versions) { ... };
 function getLatestVersionInfo (current, versions, opts) { ... };
 function getVersionsInfo (name, opts, cb) { ... };
 function getVersionsInRange (range, versions, loose) { ... };
 function isScm (version) { ... };
 function isStable (version) { ... };
 function isUpdated (dep, opts) { ... };
 function normaliseDeps (deps) { ... };

The verb 'is' implies that result will always be a Yes/No, thus a "boolean".
If another developer would later write functions to this code, it would
be highly scorned to have:

 function unstableStatus (version) { ... };

Instead, one should follow conventions and have:

 function isUnstable (version) { ... };

The conventions are often per-project, and they are formed somewhat based
on the "will" of the lead engineers at the beginning of the project.
There are variations in this area, and 

-----


Chapter ?X: Technical - Excluded in this thesis
===============================================

This thesis concentrates on processes, people, and technology that
directly contribute to software. Whereas the reality is that
all software needs to be run on a "hardware", for reasons of
scope the hardware considerations are ruled out. Thus all computing
happens on a kind of reference architecture, somewhat described
by the "von Neumann" chapter. 

Computing hardware and its role in security
- what is the class of attack, that exploits physical hardware properties
  - couple of examples
  - SSH (secure shell) RAM memory being swapped to unsafe places
    without first overwriting it with zeros
    - SSH Communications patched the code later
  - similar bug with SSH clone, "Putty" (software)
    "PuTTY vulnerability private-key-not-wiped-2" (in Putty 0.63, fix in 0.64)
    [URL http://www.chiark.greenend.org.uk/~sgtatham/putty/wishlist/private-key-not-wiped-2.html]


Unit tests: Coverage
 - two kinds of coverage

 - understanding the coverage and details of what the term itself
   means (and whether referring to "line coverage" or "branch coverage")
   are important
 - a SW team might have a separate QA engineer and/or QA team for quality
 - writing unit tests often falls to the developers themselves
 


Tools of the trade: What developers use during Software project?
================================================================
Compilers
also "transpilers"

Build chains
Automation
Scripts
Linux/Windows/Mac

Technical solutions: disk space, etc.
Backup systems
'git' and other repository technologies (storing source code)
Sketching tools for rapid prototypes
Documentation and Tickets (quality assurance)
Time tracking tools

Environments (IDE) for doing code
Communications: team collaboration tools
Statistics and metrics

- tools have diversified
- what is the trend of teams, in terms of # of tools used?
  increasing, staying same, or decreasing?
  - does simplicity have a positive effect on project metrics?
    - and does a specific tool have short payback period in terms of investment?



Chapter ?x: Software project Tool payback investment calculations
Any tool implementation should be considered as Investment
- basic formula
  -
  



II Nature of software development

2.1 The Paradigms (historical)

Paradigms during the ages Object oriented (Oo) 

All major paradigms of programming have kind of had
their "promise of an elegant solution" to the general
hardness of making consistently good, understandable
and maintainable code. In Oo, the promise goes along
this way: "Since software emulates real world, design
your code around Objects. These objects should mimic
the real world's objects, so that if you have a 'car'
in your software, make a data structure that has
the qualities of a real car, and then make functions
that operate on these qualities, and instantiate
Car Objects. The rest will follow."

Object oriented programming


2.2 Software Patterns

Patterns are largely language-independant
They're "recipes" for certain classes of problems

Software can be reduced to a "standard form" using AST. The
tree is particular to each programming language. Usually AST
is produced during a compilation (build). 

  Can AST be produced automatically from any given (binary)
  program?
 
  This product (the tree), is particular to a programming language.
  If, for example, one would obtain a binary executable program,
  without any knowledge of which language and compiler was used
  to produce it, a AST cannot be produced.
  
  Thus the reduction step can be carried out if there are
  2 things available: the complete source code of a program,
  and the language knowledge. 


(See: "Abstract Syntax Tree")
Instead of looking at the human-readable source code, when a program
is reduced to AST, the humane namings etc. are reduced to registers
(essentially an ordered set of memory locations with specific sizes).

2.3 Software Lifecycle

Formal model(s)

2.3.1

[WIP: insert Figure ]

2.4 Known project pain-points in many SW projects

- stagnation
  - similar as diminishing returns in economics
  - mathematically: the complexity of the whole project increases,
    making new features gets harder
  - psychologically might be also about project "novelty" waning, people
    less enthusiastic
  
Steps
=====

- define the scope of a Software project (should be quite formal)
  - best practices in industry?

- define the variables (metrics) of a SW project
- make functions that 


Research problem statement
==========================
'Can software security be improved while maintaining costs savings?'

 ie. Is there a process to keep quality high while not adding too much of
     overhead into programming?

=> If such a process exists, how can it be discovered? (Master's)
   + taught to a SW Team, and quality kept up (preventing fall-back to
     "bad practices")

Hypotheses
==========
- H0: 'No can do.'
      quality and costs are interchangeable (ie. not possible to lower costs
      while keeping quality at same or higher level)
      
- H1: 'It is possible.'
      Software Quality can be increased while maintaining or lowering costs,
      by understanding that security issues are partly due to wrong methodology
      in SW engineering. Attack methodology as root cause of low quality.
      

How long is a proper time span?
- The hypotheses might be impossible to inspect in too short period of time
- it takes some time to make a proper sized SW project
- and check what its quality is in "real world"
  - # of post-live defects
  - # of incidents realized

Basics

The concept of "Software": introduction
- software: control instructions for computer 
- increasing abstraction: more power to developers
- different languages exist
- shared code
- typical development process in Software engineering
  Small example with a calculator (has GUI)
- modes of deployment

What does it mean a software is insecure?
- does not work as it was designed
- design may not have up-front taken into account security aspects
- security features may be insufficient or outright phony
- reality is that software will always contain some bugs
- the choice of *which bugs* may be in the hands of the software team
- typically more security means more costs in making the software (time used)


Computer as a machine (the paradigm of von Neumann)
 https://en.wikipedia.org/wiki/Von_Neumann_architecture

Coalescence: Rise of open source software
 * CatB: The Cathedral and Bazaar (comparing two opposing views of software engineering)
 * technical infrastructure apt for the open source
 * benefits
 * drawbacks


This Thesis Paper should..
 - give advice as to whether certain New Methodology is better
   than old bag of knowledge
   - might advice on future research on change management
     to get the Management and Team follow the NM

Setup
- real or invented project?
- working from scratch or joining a already existing project?

 Scoping the state of project upon entry
  - is there a particular "problem state" or Show-stopper, right now?
  - or a feeling of being "generally stuck" etc

III "von Neumann" computing platform

a von Neumann architecture

[WIP:Figure]


The Occam problem in selecting suitable libraries
=================================================
You're about to read or sing for a child in bed.
The situation requires quick actions; if you linger on,
your child gets frustrated. If you use wrong tools, you
will eradicate his need for sleep and he gets angry,
too. By selecting "just the right tool" (ie. a flashlight
with not too intense light) you are able to read
the story, without bringing too much light into the room.
However, as usual, mr. Murphy gets involved: "Where is that
flashlight?" -> searching costs. Judgment. Heuristics. Etc.

This story has a reminiscent in software engineering. Often
developers are aware of "existence of tools capable of solving
a practical problem", and intriguingly, nowadays the question
is more "What is the _right_ tool to do the task".

There are many ways to tackle such a selection problem;
some more "professional" or formal ways are to
- enumerate the choices
- evaluate the choices based on various methods and metrics
- choose a solution out of the candidate group
- possible be ready to yank the solution out and make another
  choice

Some Heuristics in "library selection problem"

Occam's razor is a philosophical tool that advises to choose
the simplest "thought" to suit a particular phenomena. In software,
Occam's principle might advise to choose the simplest solution.

However, contrary to this heuristic, programmers often think
grandiose: Slamming as many flies with one go as possible. Thus
the choice might be something else than the simplest.

Open-source and especially open registries of software have
exploded the market: ever smaller units (packages) are being
published, and thus creating at least a theoretical opportunity
for deeper scrutiny of the ingredients of software. Linus Torvalds
has said something that became the "Linus' Law":

  given enough eyeballs, all bugs are shallow.

===================================================================

Appendix 1: How come 'Heartbleed' was possible? 2 years in the dark

One of the surprising "news bombs" was the Heartbleed, a rather
minimal amount of flawed code, which nevertheless was positioned
in a critical place in the core of Internet security. The vulnerability
had the potential to endanger a vast amount of user passwords
and private information throughout millions of servers (PCs) connected
to the Internet. 

Heartbleed (officially CVE-2014-0160) is a security bug in OpenSSL
library, which is a widely used implementation of the
Transport Layer Security (TLS) protocol. Heartbleed was introduced
into the software in 2012, and publicly disclosed in April 2014.

The amount of server exploitation enabled by Heartbleed is unknown.
Heartbleed exploitation does not leave traces to logs, and thus the damage
quantity is hard to estimate.

-> How come Heartbleed could happen?
-> Why the vulnerability was undetected for years?
- the lines of code #
   - remedy:
     - administrators: patch the server (change OpenSSL to
       non-vulnerable version)
       - make sure the vulnerability is not re-introduced by automatic
         "update" to OpenSSL
     - on user side: "Change your password"
       - if you change it before the server, that has Heartbleed,
         is patched then changing is not useful at all

Contrary:
 Heartbleed


Software Tools: Theoretical basis
=================================
To do effective measurement of various processes, each process must produce
metrics (Data) that is consistent and reliable. The production should be
economical; otherwise the scope of research is limited due to practical
issues with amount of hours put in to the research.


The basic model: A process
==========================

[WIP: Figure 3]
See the sample software process for Agile 2010-2016
- scan the page in


Several processes
==========================


How to compare the processes: Making 'ceteris paribus' real
===========================================================

In order to compare processes, it's vital to keep other things
similar; in latin, "ceteris paribus". This is the research
assumption that economics uses. Software engineering might have
similarities to economics, since we are talking about human
activity, time, resources, behavior, and incentives (and
disincentives aka. "penalty").

When I first thought of the thesis subject, I found that the
comparability might be a unsurmountable problem. I didn't
see any viable situation in real life (in software industry),
where I could keep other things intact (the team composition,
scope of project, subject of the project) while playing
god and altering just the process.



"The process" in our case is a Software engineering process:
[Figure] 

- quantifying the amount of pure in-house code vs. libraries
  - 'sloc' enhanced
- metrics ongoing
  - SLOC total in project
    - deltas per modules
    - sw modules can be classified into {tags}, or similar project management
      things
- incident count (known public vulnerabilities)
- occurrence
- Markovian
- stochastic simulation for bombardment of the software ("live" situation)

Tools: The setup of software for this thesis project
- "let me do my things": justification for automating most of the tools
- automation is king
- getting easy metrics
- making simple new tools?
  - one of the justification for small new tools is that digging into
    4+ projects might need tooling
    (ie. if projects have different set ups; different technology used)

Quality metrics for this paper
- Quality defined properly using international IEEE standards
  - and any relevant Quality circle terminology

Nature of Security: Special attention required here
- pre-disclosure risk
- post-disclosure risk
  (Cadariu_2014)


Further research topics
=============================================================
1. Long-term viability of code
   - inspection of code change in a repository through years
   -> seeing patterns in what kind of code is stable
      - reasons might not be obvious at all
      - one possible explanation is "Too precious to remove",
        and/or "No one knows what exactly it does",
	"Too interconnected" (lot of downstream dependencies)
   -> social, meritocratic facets


References 

1. "Tracking known security vulnerabilities in third-party
   components"
   [1:Tracking]
   Master' thesis, Mircea Cadariu 2014
   local file: thesis-mircea.pdf

2. "Analyzing Software Development as a Noncooperative Game"
   [2:GameTheory]
   https://www.cs.uic.edu/~drmark/index_htm_files/SDGames.pdf
   Mark Grechanik, Dewayne E. Perry
   ARISE (The Center for Advanced Research In Software Engineering)
   The University of Texas at Austin

3. "Cathedral and Bazaar"
   [3:CatB]
   Eric Raymond
   an essay of two different models of software development

4. Domains (mathematical theory of programming)
   https://www.cs.rice.edu/~javaplt/311/Readings/domains.pdf

5. "Dreaming in Code" (book)
   Scott Rosenberg

6. Ross Anderson: a paper on Information Security:
   "Why Cryptosystems Fail" (WCF)
   1993
   https://www.cl.cam.ac.uk/~rja14/Papers/wcf.pdf

7. David Modic
   Security researcher
   Cambridge University
   https://david.rodbina.org/

8. Why software is insecure? (Symantec)
   https://www.symantec.com/connect/articles/castles-built-sand-why-software-insecure

9. U.S. FTC charges D-Link
   'FTC Charges D-Link Put Consumers’ Privacy at Risk Due to the
   Inadequate Security of Its Computer Routers and Cameras'
   5.1.2017
   https://www.ftc.gov/news-events/press-releases/2017/01/ftc-charges-d-link-put-consumers-privacy-risk-due-inadequate

Journal of my writing this thesis
25.1.2017 adding Ross Anderson on Information Security economics
26.1.2017 link to 1 authors and 1 article
29.8.2017 Minor edits, called also professor at Aalto university
x.12.2017 designing the method for data gathering for projects (sources)
2018 summer: advancing the thesis, making models, gathering data
18.5.2018 Beginning with HackerOne site ("extras")
19.5.2018 Adding financial model of SW cost, basic (v1)


Useful links to tools for writer:
 Editing text in Emacs efficiently
  1. http://ergoemacs.org/emacs/emacs_abbrev_mode.html
